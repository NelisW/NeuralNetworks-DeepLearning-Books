% -*- TeX -*- -*- UK -*- -*- Soft -*-

\chapter{Exploring Bayesian Theory}
\label{chap:ExploringBayesianTheory}

\section{Drug Testing}
\label{sec:drugtesting}
This example is taken from \cite{WikiPediaBayesTtheorem2019}.

Suppose that a test for using a particular drug is 99\% sensitive and 99\% specific. That is, the test will produce 99\% true positive results for drug users and 99\% true negative results for non-drug users. Suppose that 0.5\% of people are users of the drug. What is the probability that a randomly selected individual with a positive test is a drug user?

\begin{equation}
\begin{aligned} P(\text { User } |+) &=\frac{P(+| \text { User }) P(\text { User })}{P(+)} \\ &=\frac{P(+| \text { User }) P(\text { User })}{P(+| \text { User }) P(\text { User })+P(+| \text { Non-user) } P(\text { Non-user })} \\ &=\frac{0.99 \times 0.005}{0.99 \times 0.005+0.01 \times 0.995} \\ & \approx 33.2 \% \end{aligned}
\end{equation}

Even if an individual tests positive, it is more likely that they do not use the drug than that they do. This is because the number of non-users is large compared to the number of users. The number of false positives outweighs the number of true positives. For example, if 1000 individuals are tested, there are expected to be 995 non-users and 5 users. From the 995 non-users, 0.01$\times$995$\approx$10 false positives are expected. From the 5 users, 0.99$\times$5$\approx$5 true positives are expected. Out of 15 positive results, only 5 are genuine.

The tree diagram illustrates the drug testing example with specificity at 99.5\%. $U$, $\overline{U}$, $+$ and $-$ are the events representing user, non-user, positive result and negative result. Percentages in parentheses are calculated.
\begin{marginfigure}
\includegraphics{p05c02-00a}
\end{marginfigure}
The importance of specificity in this example can be seen by calculating that even if sensitivity is raised to 100\% and specificity remains at 99\% then the probability of the person being a drug user only rises from 33.2\% to 33.4\%, but if the sensitivity is held at 99\% and the specificity is increased to 99.5\% then the probability of the person being a drug user rises to about 49.9\%.



\section{Counting Balls}
\label{sec:CountingBalls}
\subsection{The Frequentist Way}
\label{sec:TheFrequentistWay}

McElreath \cite{McElreath2015} considers the problem of drawing coloured balls from a bag.  The bag is known to contain four balls, either white [W] or blue [B].  Three balls are drawn from the bag, the colour noted and the ball returned to the bag: on each draw there will be the same four balls in the bag.

Three balls are drawn as follows: [BWB]. What is the contents of the bag, how many white balls and how many blue balls?  There are five different conjectures and for each of these conjectures the number of ways to produce the draw is shown in the figure.
\begin{marginfigure}
\includegraphics{p05c02-01}
\end{marginfigure}
The ways to produce the draw is found by multiplying for each conjecture the number of possible ways that each of the drawn balls could appear.  The draw produced blue and while balls, hence the first and the last conjecture are unable to produce the observed draw (0 ways). For each of the remaining conjectures the number of production ways are non-zero, reaching a maximum of nine, for the [BBBW] conjecture --- clearly this is the most plausible (but certainly not the only) bag contents.  At a much lower likelihood the [BWWW] bag contents could also produce the observed draw.
%By normalising ($n$/(0+3+8+9+0)) for the number of ways, the likelihood for the bag contents is
%[WWWW]=0\%, 
%[BWWW]=15\%,
%[BBWW]=40\%,
%[BBBW]=45\%, and
%[BBBB]=0\%.  These values represent the certainty we have for each of the conjectures.

\subsection{Using Prior Information}
\label{sec:UsingPriorInformation}

Using the results from the first three draws above, and we draw a fourth ball, what can we learn about the bags?  Suppose the fourth ball is blue [B].  Extend the previous calculation, and note how many ways a blue ball can be drawn.
\begin{marginfigure}
\includegraphics{p05c02-02}
\end{marginfigure}
Then multiply each of these new counts by the prior numbers of ways for each conjecture (the motivation for this follows below).  The diagram shows the bag contents likelihood if  drawing the following four balls:  [BWBB].
In this example the prior information is the first three balls drawn, the prior data and the new draw are of the same type (balls drawn).  Prior information may also arise from other sources, not just previous draws.

McElreath \cite{McElreath2015} continues his example by informing that 
someone from the marble factory tells you that blue marbles are rare. So for every bag containing [BBBW], they made two bags containing [BBWW] and three bags containing [BWWW]. They also ensured that every bag contained at least one blue and one white marble.
This prior information is multiplied with the counts after the four balls drawn thus far.
\begin{marginfigure}
\includegraphics{p05c02-03}
\end{marginfigure}
%By normalising ($n$/(0+9+32+27+0)) for the number of ways, the likelihood for the bag contents, based on four draws and the factory prior information, is
%[WWWW]=0\%, 
%[BWWW]=13.2\%,
%[BBWW]=47.1\%,
%[BBBW]=39.7\%, and
%[BBBB]=0\%.  These values represent the certainty we have for each of the conjectures.

How is prior information obtained?  Prior information can be based on previous data (previous draws in this case), but more often on 'other' sources of information, such as a model of the process or the problem context. In the absence of prior information, unity values (a.k.a. \textit{flat priors}) can be assumed.  McElreath  calls this the \textit{Principle of Indifference} or \textit{Ignorance Priors}: When there is no reason to say that one conjecture is more plausible than another, weigh all of the conjectures equally. ``The principle of indifference results in inferences very comparable to mainstream non-Bayesian approaches [i.e., frequentist], most of which contain implicit equal weighting of possibilities. For example a typical non-Bayesian confidence interval weighs equally all of the possible values a parameter could take, regardless of how implausible some of them are.''\cite{McElreath2015}  Although McElreath ``does not endorse ignorance priors'' many problems use such ignorance or flat priors as starting values, and update these as the problem is developed or better understood.


