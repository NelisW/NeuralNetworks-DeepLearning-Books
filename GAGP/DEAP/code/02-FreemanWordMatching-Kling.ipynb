{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeman's Word Matching Problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is defined by James Freemand in his book Simulating Neural Networks with Mathematica.\n",
    "The problem is studied in Chapter 9, Introduction to Genetic Algorithms by S.N. Sivanandam.\n",
    "\n",
    "The wordmatching problem tries to evolve an expression of ''to be or not to be'' from the randomly generated lists of letters with genetic algorithm. Since there are 26 possible letters for each of 13 locations in the list, the probability that we get the\n",
    "correct phrase in a pure random way is (1/26)13 = 4.03038∗10e−19, which is about two chances out of a billion.\n",
    "\n",
    "We use a list of ASCII integers to encode the string of letters. The lower case\n",
    "letters in ASCII are represented by numbers in the range [97,122] in the decimal\n",
    "number system. For example, the string of letters `tobeornottobe` is converted into\n",
    "the following chromosome represented with ASCII integers:\n",
    "[116,111,98,101,111,114,110,111,116,116,111,98,101].  Lowercase ASCII character have integer codes\n",
    "\n",
    "\n",
    "## Kling Implementation\n",
    "\n",
    "In [Learning DEAP from examples](https://www.amazon.com/Learning-DEAP-examples-Evolutionary-evolutionary-ebook/dp/B06XHXD2SF) Ronn Kling implements the problem in DEAP, solving for a four letter word such as `test` [116,101,115,116].  Keep to lowercase  and don't use spaces.\n",
    "\n",
    "The DEAP scripts can all be quite similar if the standard DEAP functions are used.\n",
    "See the [02-travelling-salesman.ipynb](https://github.com/NelisW/NeuralNetworks-DeepLearning-Notes/blob/master/GAGP/DEAP/code/02-travelling-salesman.ipynb) notebook for more detail on the standard DEAP code, the code will be used here with minimal additional comments.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import array\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from deap import  algorithms\n",
    "from deap import  base\n",
    "from deap import  creator\n",
    "from deap import  tools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the word to be constructed\n",
    "targetString = 'test'\n",
    "lenstr = len(targetString)\n",
    "# convert to ASCII representation\n",
    "stringToMatch = [ord(c) for c in targetString]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first attempt at a fitness function compares the absolute distance between the target ASCII ordinal number and the individual ASCII ordinal number, character by character.  Kling points out that this does not work, because of the `abs()` function, where the distance between s and t is the same as the distance between u and t, these appear the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalString(individual):\n",
    "    match = [0] * len(stringToMatch)\n",
    "    for i in range(0,len(stringToMatch)): \n",
    "        match[i] = (abs(individual[i] - stringToMatch[i]))\n",
    "    inputString = [chr(c) for c in individual] # turn the numbers into characters\n",
    "    print(inputString, end='\\r') # display them all on the same line\n",
    "    return tuple(match) # has to be a tuple!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second fitness function minimise the number of negative differences and the number of positive differences (remember that the first function cannot distinguish between the two).  The function returns only two values, the numbers of negative and positive differences. These two differences are calculated across the length of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalStringMinPos(individual):\n",
    "    match = [0.0, 0.0]\n",
    "    for i in range(0, len(stringToMatch)) :\n",
    "        if ((individual[i] - stringToMatch[i]) < 0.0) :\n",
    "            match[0] = match[0] + 1\n",
    "        if ((individual[i] - stringToMatch[i]) > 0.0) :\n",
    "            match[1] = match[1] + 1\n",
    "    inputString = [chr(c) for c in individual] # turn the numbers into characters\n",
    "    print(inputString, end='\\r') # display them all on the same line\n",
    "    return tuple(match) # has to be a tuple!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following operators are used in the model:\n",
    "\n",
    "`cxTwoPoint` takes a segment of the gene, defined by a start and end point, and swaps it with the other parents segment.\n",
    "\n",
    "`mutShuffleIndexes` ensures that no new values are introduced into the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupAndRun(popsize,evalFun):\n",
    "\n",
    "    # create fitness method\n",
    "    creator.create(\"FitnessMin\", base.Fitness,weights=tuple([-1.0 for i in targetString] ))\n",
    "    # create individual method\n",
    "    creator.create(\"Individual\",list, fitness=creator.FitnessMin)\n",
    "    # toolbox\n",
    "    toolbox = base.Toolbox()\n",
    "    # create the random ASCII attributes: a->97, z->121 (both values inclusive)\n",
    "    toolbox.register('attrASCII',random.randint,97,122)\n",
    "    # create the individual and population generating methods\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attrASCII,len(stringToMatch))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)    \n",
    "    # register the crossover operator\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    # register a mutation operator\n",
    "    toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # register the goal / fitness function\n",
    "    toolbox.register(\"evaluate\",evalFun)\n",
    "\n",
    "    random.seed(64)\n",
    "    # create a small initial population individuals (where each individual is a list of integers)\n",
    "    pop = toolbox.population(n=300)\n",
    "    #only save the very best one\n",
    "    hof = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    # use one of the built in GA's with a probablilty of mating of 0.7\n",
    "    # a probability of mutating 0.2 and 140 generations.\n",
    "    algorithms.eaSimple(pop, toolbox, 0.7, 0.2, 140, stats=stats,\n",
    "    halloffame=hof, verbose=0)\n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    print(f'Best individual = {best_ind}, fitness = {best_ind.fitness.values}')\n",
    "    inputString = [chr(c) for c in best_ind]\n",
    "    print(f'best guess={inputString}', end='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetString = test\n",
      "Best individual = [116, 101, 115, 115], fitness = (0.0, 0.0, 0.0, 1.0)\n",
      "best guess=['t', 'e', 's', 's']\n"
     ]
    }
   ],
   "source": [
    "print(f'targetString = {targetString}')\n",
    "setupAndRun(popsize=300,evalFun=evalString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetString = test\n",
      "Best individual = [116, 101, 115, 115], fitness = (0.0, 0.0, 0.0, 1.0)\n",
      "best guess=['t', 'e', 's', 's']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
